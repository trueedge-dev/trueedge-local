TRUEEDGE – BACKEND PROTOTYPE PLAN (DRAFT v0.1)

PURPOSE:
Define how to evolve from a purely local logger to a simple backend service that:

- receives TRADE_EVENT objects over HTTP(S),
- stores them in a real database (not just a file),
- exposes metrics via API and a small web UI.

This is an architectural plan for the first backend prototype, not final production design.

--------------------------------------------------
1. TARGET SHAPE OF THE BACKEND (MINIMUM VIABLE SERVICE)
--------------------------------------------------

The backend should do three main things:

1) Ingest trades:
   - Endpoint: POST /trade_event
   - Input: JSON TRADE_EVENT (same schema as local_logger)
   - Action:
       - validate event (reuse trade_event_validator logic),
       - store in persistent database (e.g. SQLite initially),
       - possibly compute/update basic aggregates (optional).

2) Serve metrics:
   - Endpoint: GET /metrics/overall
   - Endpoint: GET /metrics/by_strategy
   - Endpoint: GET /metrics/by_account
   - Later variants with query parameters:
       - /metrics/strategy/{strategy_id}
       - /metrics/account/{account_id}
   - Output: JSON with metrics:
       - total_trades, total_pnl, ending_equity, max_drawdown, wins, losses, win_rate

3) Serve simple HTML reports:
   - Endpoint: GET /report
       - returns HTML similar to reports/index.html but generated by the backend.
   - Later: dynamic pages per strategy/account.

In early prototype, all of this can run on a single process, single host, with:

- Python standard library or a small web framework,
- SQLite as the database (file-based, easy to deploy).

--------------------------------------------------
2. DATA STORAGE CHOICE (FIRST ITERATION)
--------------------------------------------------

Initial choice: SQLite.

Reasons:
- Included in Python standard library (`sqlite3` module).
- File-based database (one .db file on disk).
- Good enough for:
   - local testing,
   - single-user or low traffic,
   - proof of concept.

Basic schema (draft):

- trades table:
    - id (integer primary key, auto increment)
    - event_id (text, unique)
    - account_id (text)
    - strategy_id (text)
    - environment (text)
    - venue (text)
    - timestamp (text)
    - symbol (text)
    - side (text)
    - order_type (text)
    - quantity (real)
    - quantity_type (text)
    - price_open (real)
    - price_close (real)
    - fees (real)
    - pnl (real)
    - state (text)
    - raw_json (text)  <-- full original JSON as backup

Later, we can normalize more tables (accounts, strategies, portfolios), but for prototype a single `trades` table is enough.

--------------------------------------------------
3. API DESIGN (BACKEND)
--------------------------------------------------

Base URL: for local testing, something like:
- http://127.0.0.1:9000

Endpoints (v0):

1) POST /trade_event
   - Body: JSON TRADE_EVENT
   - Steps:
       1. Parse JSON.
       2. Validate using the same logic as local_logger (import shared validator).
       3. Insert into SQLite database.
   - Response:
       - 200 OK on success:
           { "status": "ok" }
       - 400 on validation error:
           { "status": "error", "message": "...validation info..." }

2) GET /metrics/overall
   - Query:
       - optional: ?account_id=...&strategy_id=...
   - Steps:
       1. Fetch trades from DB (all or filtered).
       2. Compute metrics using shared metrics_core functions.
   - Response:
       - 200 OK, JSON with metrics dict.

3) GET /metrics/by_strategy
   - Steps:
       1. Group trades by strategy_id in DB query or in Python.
       2. Compute metrics per strategy.
   - Response:
       - 200 OK, JSON:
           {
             "strategies": [
                { "strategy_id": "...", "metrics": {...} },
                ...
             ]
           }

4) GET /metrics/by_account
   - Same pattern as by_strategy.

5) GET /report
   - Steps:
       1. Fetch events.
       2. Compute metrics.
       3. Render a simple HTML page (similar to current local report).
   - Response:
       - 200 OK with Content-Type: text/html.

Security and auth:
- First prototype: no authentication (local only, safe testing).
- Later: simple API keys or header-based tokens.

--------------------------------------------------
4. IMPLEMENTATION STRATEGY (STEP-BY-STEP)
--------------------------------------------------

We evolve from local to backend in careful steps:

STEP 1 – Shared core modules:
- Ensure trade_event_validator and metrics_core are reusable by both:
   - local_logger,
   - api_backend.

STEP 2 – Minimal backend server:
- Choose a simple approach:
   - either Python's built-in http.server with manual routing,
   - or a lightweight framework (like FastAPI/Flask) once allowed.
- Implement:
   - /trade_event (POST),
   - /metrics/overall (GET),
   - /metrics/by_strategy (GET),
   - /metrics/by_account (GET).

STEP 3 – SQLite integration:
- Create db_init function to:
   - connect to SQLite .db file (e.g. trueedge.db),
   - create trades table if not exists.
- Implement insertion of validated TRADE_EVENT into the trades table.
- Implement queries for metrics endpoints.

STEP 4 – HTML report endpoint:
- Reuse logic from generate_html_report, but:
   - instead of reading .jsonl files,
   - read from SQLite.
- Return HTML string as HTTP response.

STEP 5 – Config and deployment basics:
- Simple config file or env variables for:
   - DB path,
   - host/port.
- Later:
   - containerize (Docker),
   - deploy to a cheap cloud service.

--------------------------------------------------
5. HOW THIS CONNECTS BACK TO MONEY PLAN
--------------------------------------------------

This backend is the technical foundation of:

- PATH A (tooling/consulting for small funds/props):
   - They could host their own TRUEEDGE backend,
   - or we deploy/manage one for them.

- PATH B (TRUEEDGE Cloud):
   - This prototype, once hardened and moved to a real host,
     becomes the first version of the hosted service:
     - SaaS dashboard and metrics API.

We are not implementing users, billing, or complicated auth yet.
We first make sure: trade ingestion + metrics via SQLite + HTTP works reliably.

--------------------------------------------------
6. NEXT ACTIONS FROM THIS PLAN
--------------------------------------------------

Immediate next steps (code level):

- Create an api_backend folder in 02_CODE/.
- Add a small README for api_backend prototype.
- Implement a minimal backend server that:
   - starts on localhost:9000,
   - accepts POST /trade_event,
   - validates and writes to a SQLite database,
   - exposes at least GET /metrics/overall using DB-backed metrics.

Later:

- Add /metrics/by_strategy and /metrics/by_account.
- Add /report HTML endpoint.
- Add very simple auth or separate dev/test DBs.
